{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import librarries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Super vised ML \n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, root_mean_squared_error, r2_score\n",
    "\n",
    "# Regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# Hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading train, test\n",
    "# Filtering, Scaling, encoding test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/EDA intermediate datasets/16_X_train_scaled_encoded.csv\")\n",
    "y_train = pd.read_csv(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/EDA intermediate datasets/13_y_train.csv\")\n",
    "X_test = pd.read_csv(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/EDA intermediate datasets/14_X_test.csv\")\n",
    "y_test = pd.read_csv(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/EDA intermediate datasets/15_y_test.csv\")\n",
    "X_test_filtered = X_test.loc[:, X_train.columns]\n",
    "X_test_filtered.to_csv(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/EDA intermediate datasets/17_X_test_filtered.csv\")\n",
    "scaler_encoder = joblib.load(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/Models/Transform models/feature_scaler_encoder.pkl\")\n",
    "X_test_scaled_encoded = scaler_encoder.fit_transform(X_test_filtered)\n",
    "X_test_scaled_encoded = pd.DataFrame(X_test_scaled_encoded)\n",
    "X_test_scaled_encoded.to_csv(r\"C:/ML Projects/Diamond Price Prediction/Artifacts/EDA intermediate datasets/18_X_test_scaled_encoded.csv\")\n",
    "X_test = X_test_scaled_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\n",
    "            \"Linear Regression\": LinearRegression(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            \"Linear Regression\":{}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_regression(X_test, true, predicted) :\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    adj_r2_square = 1 - (1 - r2_square) * (len(true) - 1)/(len(true) - X_test.shape[1] - 1)\n",
    "    return mse, mae, rmse, r2_square, adj_r2_square \n",
    "    \n",
    "report = {}\n",
    "model_params = {}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    para = params[list(models.keys())[i]]\n",
    "\n",
    "    gs = GridSearchCV(model, para, cv = 3, scoring = \"r2\")\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    model.set_params(**gs.best_params_)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    values = evaluate_model_regression(X_test, y_test, y_test_pred)\n",
    "    report[list(models.keys())[i]] = {var: val for var, val in zip(('mse', 'mae', 'rmse', 'r2_square', 'adj_r2_square'), values)}\n",
    "    model_params[list(models.keys())[i]] = dict(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear Regression': {'mse': 1209259.6799586136, 'mae': 810.6408367324608, 'rmse': 1099.6634394025355, 'r2_square': 0.9251676095321284, 'adj_r2_square': 0.9251579435125377}}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear Regression': {}}\n"
     ]
    }
   ],
   "source": [
    "print(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression 0.9251579435125377\n"
     ]
    }
   ],
   "source": [
    "best_model_score = 0\n",
    "for key1, value1 in report.items() :\n",
    "    if value1['adj_r2_square'] > best_model_score :\n",
    "        best_model_score = max(best_model_score, value1['adj_r2_square'])\n",
    "        best_model = key1\n",
    "print(best_model, best_model_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
